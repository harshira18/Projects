Text detection in scene images is the process of precisely localizing instances of text in them. This detection is required for a plethora of computer vision applications including text recognition, autonomous vehicles, script narrators, translation apps etc. However, this task is accompanied by its own challenges. Diversified text shapes, complex backgrounds, noise, irregular orientation etc. are the several hinderances for text detectors.

Scene text detection was mostly limited to putting together handcraftedÂ low-level attributes of the texts contained in images until the emergence of deep learning in this area. Recently developed neural network-based scene text detection methods have produced impressive results. Text detection in scenic images is an ongoing research area, and the performance of different techniques vary based on the specific challenges presented by the images. A combination of methods or exploring domain-specific approaches help in enhancing the efficacy of detecting text in scenic images.

Here we have implemented and assessed the performance of three text detection models namely; EAST, CRAFT and TextFuseNet on two benchmark public datasets. We observed that TextFuseNet outperforms the other two models by achieving an F-measure of 94.6% and 92.2% on ICDAR-2013 [20] and ICDAR-2015 [21] respectively, followed by CRAFT [89.8%, 84.8%] and EAST [85.3%, 80.7%].
